,0
units,512
nr_hidden_layers,2
loss_fn,mean_squared_logarithmic_error
optimizer,Adam
hidden_activation,leaky_relu
output_activation,relu
kernel_regularization,<tensorflow.python.keras.regularizers.L2 object at 0x7f0c8d409e80>
bias_regularization,<tensorflow.python.keras.regularizers.L2 object at 0x7f0c8c5d2a90>
dropout,False
dropout_rate,0.1
learning_rate,2e-07
epochs,150
batch_size,48
scaling,False
logarithm,False
